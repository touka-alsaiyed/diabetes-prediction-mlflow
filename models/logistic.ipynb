{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, ConfusionMatrixDisplay, classification_report\n",
    "from mlflow.models.signature import infer_signature\n",
    "from hyperopt import fmin, tpe, hp, Trials, STATUS_OK\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load preprocessed dataset\n",
    "df = pd.read_csv(\"/Users/touka/Desktop/BAU/forth year/s2/AIN3009/project/Mlflow_project/data/diabetes_cleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate Features and Target\n",
    "X = df.drop(\"Outcome\", axis=1)\n",
    "y = df[\"Outcome\"]\n",
    "\n",
    "# Split into Train/Test Sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Scale features \n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to log classification metrics and artifacts to MLflow\n",
    "def log_classification_metrics(y_true, y_pred, prefix=\"\"):\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    prec = precision_score(y_true, y_pred)\n",
    "    rec = recall_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "\n",
    "    mlflow.log_metric(f\"{prefix}accuracy\", acc)\n",
    "    mlflow.log_metric(f\"{prefix}precision\", prec)\n",
    "    mlflow.log_metric(f\"{prefix}recall\", rec)\n",
    "    mlflow.log_metric(f\"{prefix}f1_score\", f1)\n",
    "\n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "    disp.plot(cmap='Blues', values_format='d')\n",
    "    cm_filename = f\"{prefix}confusion_matrix.png\"\n",
    "    plt.savefig(cm_filename)\n",
    "    mlflow.log_artifact(cm_filename)\n",
    "    plt.close()\n",
    "\n",
    "    # Classification Report\n",
    "    report = classification_report(y_true, y_pred)\n",
    "    report_filename = f\"{prefix}classification_report.txt\"\n",
    "    with open(report_filename, \"w\") as f:\n",
    "        f.write(report)\n",
    "    mlflow.log_artifact(report_filename)\n",
    "\n",
    "    # Clean up\n",
    "    os.remove(cm_filename)\n",
    "    os.remove(report_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'DiabetesModel' already exists. Creating a new version of this model...\n",
      "Created version '1' of model 'DiabetesModel'.\n"
     ]
    }
   ],
   "source": [
    "# Train a baseline Logistic Regression model and log parameters and model to MLflow\n",
    "mlflow.set_tracking_uri(\"file:///Users/touka/Desktop/BAU/forth year/s2/AIN3009/project/Mlflow_project/mlruns\")\n",
    "mlflow.set_experiment(\"Diabetes_Prediction_Experiment\")\n",
    "\n",
    "with mlflow.start_run(run_name=\"LR-Baseline\"):\n",
    "    mlflow.set_tag(\"model\", \"LogisticRegression\")\n",
    "    mlflow.set_tag(\"type\", \"baseline\")\n",
    "\n",
    "    model = LogisticRegression(max_iter=1000, C=1.0, penalty=\"l2\", solver=\"lbfgs\", random_state=42)\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "    mlflow.log_params({\"max_iter\": 1000, \"C\": 1.0, \"penalty\": \"l2\", \"solver\": \"lbfgs\"})\n",
    "    log_classification_metrics(y_test, y_pred)\n",
    "\n",
    "    signature = infer_signature(X_test_scaled, y_pred)\n",
    "    mlflow.sklearn.log_model(model, \"lr_model\", signature=signature)\n",
    "    mlflow.register_model(f\"runs:/{mlflow.active_run().info.run_id}/lr_model\", \"DiabetesModel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:27<00:00,  5.45s/trial, best loss: -0.7581227436823105]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Registered model 'DiabetesModel' already exists. Creating a new version of this model...\n",
      "Created version '2' of model 'DiabetesModel'.\n"
     ]
    }
   ],
   "source": [
    "# Hyperopt Tuning\n",
    "lr_space = {\n",
    "    \"C\": hp.loguniform(\"C\", -4, 2),\n",
    "    \"penalty\": hp.choice(\"penalty\", [\"l1\", \"l2\"]),\n",
    "    \"solver\": hp.choice(\"solver\", [\"liblinear\", \"saga\"])\n",
    "}\n",
    "\n",
    "def lr_objective(params):\n",
    "    if params[\"penalty\"] == \"l1\" and params[\"solver\"] not in [\"liblinear\", \"saga\"]:\n",
    "        return {\"loss\": float(\"inf\"), \"status\": STATUS_OK}\n",
    "\n",
    "    with mlflow.start_run(run_name=f\"LR-Tune-{params['penalty']}\", nested=True):\n",
    "        mlflow.set_tag(\"model\", \"LogisticRegression\")\n",
    "        mlflow.set_tag(\"type\", \"tuning\")\n",
    "\n",
    "        model = LogisticRegression(max_iter=1000, random_state=42, **params)\n",
    "        model.fit(X_train_scaled, y_train)\n",
    "        y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "        mlflow.log_params(params)\n",
    "        log_classification_metrics(y_test, y_pred)\n",
    "\n",
    "        signature = infer_signature(X_test_scaled, y_pred)\n",
    "        mlflow.sklearn.log_model(model, \"lr_model\", signature=signature)\n",
    "\n",
    "        return {\"loss\": -accuracy_score(y_test, y_pred), \"status\": STATUS_OK}\n",
    "\n",
    "lr_trials = Trials()\n",
    "best_lr = fmin(fn=lr_objective, space=lr_space, algo=tpe.suggest, max_evals=5, trials=lr_trials)\n",
    "\n",
    "penalties = [\"l1\", \"l2\"]\n",
    "solvers = [\"liblinear\", \"saga\"]\n",
    "\n",
    "final_lr_params = {\n",
    "    \"C\": best_lr[\"C\"],\n",
    "    \"penalty\": penalties[best_lr[\"penalty\"]],\n",
    "    \"solver\": solvers[best_lr[\"solver\"]],\n",
    "    \"max_iter\": 1000\n",
    "}\n",
    "\n",
    "final_lr = LogisticRegression(**final_lr_params, random_state=42)\n",
    "final_lr.fit(X_train_scaled, y_train)\n",
    "final_lr_pred = final_lr.predict(X_test_scaled)\n",
    "\n",
    "# log the best Logistic Regression model\n",
    "with mlflow.start_run(run_name=\"LR-Best-Tuned\"):\n",
    "    mlflow.set_tag(\"model\", \"LogisticRegression\")\n",
    "    mlflow.set_tag(\"type\", \"best_tuned\")\n",
    "\n",
    "    mlflow.log_params(final_lr_params)\n",
    "    log_classification_metrics(y_test, final_lr_pred)\n",
    "\n",
    "    signature = infer_signature(X_test_scaled, final_lr_pred)\n",
    "    mlflow.sklearn.log_model(final_lr, \"lr_model\", signature=signature)\n",
    "    mlflow.register_model(f\"runs:/{mlflow.active_run().info.run_id}/lr_model\", \"DiabetesModel\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlflow_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
